version: "3.9"
services:

    # FastAPI service for TelemetryGuard Stroke Prediction API
  api:
    build:
      context: ./api
      dockerfile: ./Dockerfile
    container_name: telemetryguard_api
    ports:
      - "8000:8000"
    env_file:
      - .env
    depends_on:
      - mlflow
    networks:
      - telemetryguard_net


  # MLFlow tracking server
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.10.0
    container_name: mlflow
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/mlruns #persistence layer that copies mlruns from host machine into container
      - ./mlflow.db:/mlflow.db #stores mlflow artifacts in local SQLite file (run names, metrics, params, etc.)
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri sqlite:///mlflow.db
      --default-artifact-root /mlruns
    restart: unless-stopped
    networks:
      - telemetryguard_net



  # Prometheus tracking service
  prometheus:
    image: prom/prometheus
    container_name: prometheus
    ports:
      - "9090:9090" # Prometheus dashboard at http://localhost:9090
      - "9100:9100"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml # Config tells Prometheus to scrape FastAPI /metrics endpoint
    depends_on:
      - api
    restart: unless-stopped
    networks:
      - telemetryguard_net

  # Grafana dashboard service
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"                # Grafana dashboard: http://localhost:3000
    volumes:
      - ./grafana:/var/lib/grafana # Persist dashboards
    depends_on:
      - prometheus
    restart: unless-stopped
    networks:
      - telemetryguard_net

#Shared Network Configuration
networks:
  telemetryguard_net:
    driver: bridge #creates a virtual network so containers can communicateb by name (api -> mlflow -> prometheus)